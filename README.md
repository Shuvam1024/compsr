# Super-resolution with compression
## Introduction
This project is about exploring use of deep convolutional neural networks for superresolution of images in the presence of compression and noise. In an increasingly popular and realistic image/video transmission scenario, images/videos can often be reduced in resolution and compressed before transmitting to a recipient. The recipient then decompresses the compressed bitstream and upscales to the display resolution before displaying it to a viewer. This process is happening anyway all the time when we view images on the web. The upscaling filters typically used on the receiver side are linear filters. In this project we want to investigate if and how much we can improve the quality of the final image if we used a deep Convolutional Neural Network (CNN) after the linear upscaling step. While the linear upscaling and CNN steps could be combined into one CNN superresolution step, for convenience of exploring down and upscaling ratios that are possibly fractional, in this project we keep the linear upscaling process separate from the CNN. The CNN thus operates on the linear upscaled image to produce a hopefully better quality image at the same resolution as its input.

While typical super-resolution processes deal with ratios that are 2:1 or higher, we consider down and upsampling ratios that are not just 2:1 but smaller and consequently fractional. Often the detail level at downsampling ratios higher than 2:1 are irrevocably lost, and therefore we focus on cases where there is a better chance to retrieve lost detail by a deep network. In particular we focus on the following down- and upsampling ratios: 2:1, 8:5 and 4:3.
Furthermore note that our CNN should recover from degradation induced not only by reduction in spatial resolution, but also from compression noise. Therefore, the quality of compression should be another factor that should be considered in the CNN. In particular, we focus on 4 compression levels: near-lossless-quality, high-quality, medium-quality, and low-quality, obtained with a modern video/image codec. The particular image codec we use is AV1 from the Alliance for Open Media, even though extensions to other codecs is trivial. The QP values used with AV1 to generate the 4 compression levels are: 20 (near-lossless-quality), 30 (high-quality), 40 (medium-quality), and 50 (high-quality).
We envision a scenario where different CNNs may be used for different combinations of the pair: down/up ratio and compression-level. Therefore we generate training and testing data for each pair, which is 12 in all for 3 down-up ratios and 4 compression-levels. We hereby also release these datasets
Below, we provide the steps used to generate the datasets. All the datasets are adapted from the Div2K dataset originally released for a competition on super-resolution without compression. But we are happy to make our adaptations on this set available for free to other researchers in this space.
